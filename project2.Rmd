---
title: 'TMA4315: Project 2'
author: "jototlan@stud.ntnu.no (10018), martigtu@stud.ntnu.no (10037)"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem 1
```{r}
mammals <- read.table(
  "https://www.math.ntnu.no/~jarlet/statmod/mammals.dat",
  header=T)
```

## a)
```{r}
plot(log(mammals$body), log(mammals$brain))
```


The log-log plot of the brain mass against body mass seems to reveal a linear trend. We thus fit the following model:

```{r}
mod0 <- lm(log(brain) ~ log(body), data = mammals)
summary(mod0)
```

If we let $\boldsymbol{y} = [y_1, \ldots, y_n]^T$ denote the brain mass and $\boldsymbol{x}_b = [x_{b1}, \ldots, x_{bn}]^T$ denote the corresponding body mass, we have fitted the model $\ln(y_i) = \beta_0 + \beta_1 \ln(x_{bi}))$, $i = 1,2\ldots n$, with parameter estimates given in the summary above.

## b)
The extended model is fitted below.
```{r}
mammals$is.human = as.factor(mammals$species == "Human")

mod1 <- lm(log(brain) ~ log(body) + is.human, data = mammals)
summary(mod1)
```
Let $\hat{\boldsymbol{\beta}} = \begin{bmatrix}\hat{\beta}_0 & \hat{\beta}_1 & \hat{\beta}_2\end{bmatrix}^T$ be the coefficient estimates given in the summary above, where $\hat{\beta}_2 \approx$ `r mod1$coefficients[3]` models the effect which being a human has on the (log of) brain size. Since we have used a log-transform on both the brain mass and body mass, humans will according to the model be larger by a factor of $e^{\hat{\beta}_2} =$ `r exp(mod1$coefficients[3])`.

We use the notation $\boldsymbol{y} = X\boldsymbol{\beta} + \boldsymbol{\varepsilon}$ to represent the linear model. Here, $X$ is the $n \times p$ design matrix, where $n$ is the number of observations and $p$ is the number of parameters used in the model. Here, $X = \begin{bmatrix}\boldsymbol{1} & \ln\boldsymbol{x}_b & \boldsymbol{x}_h\end{bmatrix}$, where $\boldsymbol{x}_h = [x_{h1}, \ldots, x_{hn}]^T = [0, \ldots 0, 1, 0, \ldots, 0]^T$ which has a nonzero entry $x_{hh} = 1$ only for humans only. As usual, $\boldsymbol{\varepsilon} \sim \mathcal{N}(\boldsymbol{0}, \sigma^2 I_n)$. We know that

$$
\hat{\boldsymbol{\beta}} \sim \mathcal{N}(\boldsymbol{\beta}, \sigma^2(X^TX)^{-1}).
$$
Now we want to perform the hypothesis test

$$
H_0: \beta_2 = 0 \quad \text{vs.} \quad H_1: \beta_2 > 0.
$$
Under $H_0$, we obtain that (we also index from 0 in the design matrix)

$$
\frac{\hat{\beta}_2}{\sigma\sqrt{(X^TX)^{-1}_{2,2}}} \sim \mathcal{N}(0, 1).
$$

Combining this with the fact that 
$$
\frac{(n-p)s^2}{\sigma^2} \sim \chi^2_{n-p},
$$
where $s^2 = SSE/(n-p)$, we obtain the test statistic

$$
T_1 = \frac{\hat{\beta}_2}{s\sqrt{(X^TX)^{-1}_{2,2}}} \sim t_{n-p},
$$
under $H_0$. We perform the calculations in R:
```{r}
n <- nrow(mammals)
p <- 3
beta.2.hat <- mod1$coefficients[3]
s <- sqrt(deviance(mod1)/(n-p))
X <- model.matrix( ~ log(body) + is.human, data = mammals)
XtX.inv <- solve(t(X) %*% X)


T.1 <- beta.2.hat/(s*sqrt(XtX.inv[3,3]))
p.val <- pt(T.1, n - p, lower.tail = F)
p.val
```
The calculated p-value is `r p.val`. The low p-value indicates that the difference between human brain size and expected brain size of mammals with the same body mass is positive.

## c)

We now consider all non-human mammals and construct a one-sided prediction interval for the human brain size. For ease of notation, we define $z_i := \ln y_i$ and $v_i = \ln(x_{bi})$. We also let $n' = n -1$ as the number of observations (since we exclude the observation of humans). Now,  $z_h = \beta_0 + \beta_1 v_h + \varepsilon_h$ is the stochastic variable from which the log of the human brain mass is realized and $\hat{z}_h = \hat{\beta}_0 + \hat{\beta}_1v_h$ is the corresponding estimate. Then we can find the pivotal quantity

$$
T_2 = \frac{z_h - \widehat{z}_h}{s\sqrt{1 + 1/n' + \frac{(v_h - \bar{v})^2}{\sum_{i = 1}^{n'}(v_i-\bar{v})^2}}} \sim t_{n' -2}.
$$
We refer to the good old [\textcolor{blue}{subject-pages}](https://tma4245.math.ntnu.no) (simple linear regression/prediction and prediction intervals in simple linear regression) for this result. Thus, we can find the one-sided prediction interval:

$$
P(T_2 < k) = 1 - \alpha \implies k = t_{n'-2,\ \alpha}.
$$
Rearranging, we arrive at

$$
P\left(z_h < \underbrace{t_{n'-2,\ \alpha} \cdot s\sqrt{1 + 1/n' + \frac{(v_h - \bar{v})^2}{\sum_{i = 1}^n(v_i-\bar{v})^2}} + \widehat{z}_h}_{=\ \ln U} \right) = 1 - \alpha.
$$

Raising $e$ to the power of both sides of the inequality, we get
$$
P(y_h < U) = 1-\alpha.
$$
In accordance with the task description, we define
$$
A = \{y_h \notin (-\infty,\ U)\} = \{y_h \ge U\}, \quad \text{and} \quad B = \{ T_1 \ge t_{n-p,\ \alpha}\}
$$
We now observe that $A$ is equivalent to $\{T_2 \ge t_{n'-2,\ \alpha}\} = \{T_2 \ge t_{n-p,\ \alpha}\}$, where $p = 3$ as before. To show that $A$ and $B$ are equivalent, we find the MLE of $\beta_2$ from the model in b) by considering the profile log-likelihood (here $\boldsymbol{x}_i$ denotes the $i$'th row of the previously defined design matrix) :
$$
\begin{split}
l_p(\beta_0,\beta_1) &= \sup_{\beta_2} l(\beta_0,\beta_1, \beta_2)\\
&= \sup_{\beta_2}\ln\left( \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi}\sigma}  e^{-\frac{1}{2}\left(\frac{z_i-\boldsymbol{x}_i^T\boldsymbol{\beta}}{\sigma}\right)^2}\right) \\
&= \sup_{\beta_2} \left( n\ln\left(\frac{1}{\sqrt{2\pi}\sigma}\right) - \frac{1}{2\sigma^2}\sum_{i = 1}^n (z_i-\boldsymbol{x}_i^T\boldsymbol{\beta})^2\right)\\
&= \sup_{\beta_2} \left( n\ln\left(\frac{1}{\sqrt{2\pi}\sigma}\right) - \frac{1}{2\sigma^2}\sum_{\begin{matrix}i=1\\i\ne h\end{matrix}}^n (z_i-\boldsymbol{x}_i^T\boldsymbol{\beta})^2- \frac{1}{2\sigma^2} (z_h-\boldsymbol{x}_h^T\boldsymbol{\beta})^2\right).
\end{split}
$$
Since $x_{hi}$ is nonzero for only one term in the sum above (for $i = h$) we only need to consider this term. That is, the term with $\boldsymbol{x}_h := \begin{bmatrix}1 & \ln x_{bh} & 1\end{bmatrix}^T$. The constant in front of $(z_h-\boldsymbol{x}_h^T\boldsymbol{\beta})^2$ is negative, so the supremum is attained when this is equal to zero. Thus,

$$
(z_h-\boldsymbol{x}_h^T\boldsymbol{\beta})^2 = 0 \quad \implies \quad z_h - \beta_0 - \beta_1 v_h - \beta_2 = 0,
$$

which means that $\beta_2 = z_h - \beta_0 - \beta_1v_h$. Due to the invariance of MLEs, we now know that
$$
\hat{\beta}_2 = z_h - \hat{\beta}_0 - \hat{\beta_1}v_h = z_h - \widehat{z}_h.
$$
We also note that the estimators $\hat{\beta}_0$ and $\hat{\beta}_1$ are the same here as in the case where we do not consider humans (since the term involving $\boldsymbol{x}_h$ in the log-likelihood evaluates to zero). Thus, since both $T_1$ and $T_2$ depend on the same $\hat{\beta}_2 = z_h - \widehat{z}_h$, meaning that $A$ and $B$ occur when the difference $z_h - \widehat{z}_h$ is large, we can conclude that the two events are equivalent. 

## d)
For a gamma-distributed random variable, the pdf takes the form
$$
f(x; a,b) = \frac{b^a}{\Gamma(a)} x^{a-1}e^{-bx}.
$$
Using the parametrization $\mu = \frac{a}{b}$ and $\nu = a$, we construct the GLM with a log-link as follows;
$$
y_i \sim \mathrm{Gamma}(\mu_i,\ \nu_i),
$$
with $\text{E}[y_i] = \mu_i$, such that
$$
\ln(\mu_i) = \eta_i = \boldsymbol{x}_i^T \boldsymbol{\beta}.
$$
Next, we fit the model:
```{r}
mod.gamma <- glm(brain ~ log(body) + is.human, family = Gamma(link="log"), data = mammals)
summary(mod.gamma)
```


## e)
Using the same notation as before, we want to test whether the following relationship holds;
$$
y_i = y_0\ x_{bi}^{3/4},
$$
where $y_i$ is the brain mass, $y_0$ is a constant and $x_{bi}$ is the body mass. Since this is equivalent to testing

$$
\ln(y_i) = \ln(y_0) + \frac{3}{4}\ln(x_{bi}),
$$
this simply amounts to performing the hypothesis test:
$$
H_0: \beta_1 = \frac{3}{4} \quad \mathrm{vs.} \quad \beta_1 \ne \frac{3}{4}.
$$

### Linear model
We first consider the linear model from (b), and construct a Wald test:

```{r}
# Wald test:
C <- matrix(c(0, 1, 0), nrow = 1)
d <-  as.vector(3/4)
r <- 1
p <- 3
n <-  nrow(mammals)
beta.hat <- mod1$coefficients
s2 <- deviance(mod1)/(n-p)
X <- model.matrix(mod1)
XtX.inv <- solve(t(X) %*% X)

w <- t((C %*% beta.hat - d)) %*% solve(s2*C %*% XtX.inv %*% t(C)) %*% (C %*% beta.hat - d)
p.val <- pchisq(w, r, lower.tail = FALSE)
p.val
```

The likelihood-ratio test for the linear model can be carried out as follows:

```{r}
mod1.offset <- lm(log(brain) ~ is.human, offset = 3/4*log(body), data = mammals)
anova(mod1.offset, mod1, test = 'LRT')
```

### Gamma-GLM
Next we consider the GLM from (d). For a generalized linear model, the Wald statistic can be written as

$$
w =(C\hat{\boldsymbol{\beta}} - d)^T[CF^{-1}(\hat{\boldsymbol{\beta}})C^T]^{-1}(C\hat{\boldsymbol{\beta}} - d),
$$

which is asymptotically $\chi^2$-distributed with $r = \mathrm{rank}(C)$ degrees of freedom. We compute its value:
```{r}
beta.hat <- as.vector(mod.gamma$coefficients)
w <- t(C %*% beta.hat - d) %*% solve(C %*% vcov(mod.gamma) %*% t(C)) %*% (C %*% beta.hat - d)

p.val <- pchisq(w, r, lower.tail = FALSE)
p.val
```

The liklihood-ratio test for the GLM can be carried out as follows:
```{r}
mod.gamma.offset <- glm(brain ~ 1 + is.human, family = Gamma(link = "log"),
                        offset = 3/4*log(body), data = mammals) 

anova(mod.gamma.offset, mod.gamma, test = "LRT")
```

For both the linear model and for the gamma-GLM, there is no evidence that we should reject $H_0$, which supports the hypothesis that the relationship $y_i = y_0x_{bi}^{3/4}$ holds.

We observe that the p-values for the Wald and LR-test are essentially equal for the linear model, while for the GLM, the difference is notable. The reason behind this is that the LR-test and Wald test are equivalent for the linear model. This can be shown by noting that the Wald-statistic is equal to the F-statistic, since $W = rF = F$ (see Fahrmeir p. 131). The LRT-statistic is, in turn, a strictly monotonic function of the F-statistic, which shows that the two tests are equivalent. 

For the GLM, on the other hand, this is not the case, and even though the Wald test-statistic, $w$, and the LRT-statistic, $lr$, are asymptotically equivalent, where $w,lr \overset{a}{\sim} \chi^2_r$ (Fahrmeir p. 664), they can give quite different results for finite samples. The likelihood ratio test is generally considered more reliable, which is connected to the fact that it considers the model under both hypotheses, while the Wald test only considers the model under the alternative hypothesis. Other reasons to prefer the LR-test are listed [\textcolor{blue}{here}](https://en.wikipedia.org/wiki/Wald_test#Alternatives_to_the_Wald_test).

# f)
We need to be careful comparing the log-likelihoods and hence the AICs of the models, because for the GLM we consider $Y \sim \mathrm{Gamma}$, while in the linear model we consider $\ln Y\sim \mathrm{Normal}$. To make them comparable, we define $X:= \ln(Y)$. Then (for the linear model) $Y = e^X$ and the Jacobian transformation yields a density of
$$
f_Y(y) = \left|\frac{\partial x}{\partial y}\right| f_X(x) = \frac{1}{y}f_X(x).
$$
The connection between the log-likelihoods are thus
$$
l_Y(\boldsymbol{\beta}) = l_X(\boldsymbol{\beta}) -\sum_{i = 1}^n \ln y_i,
$$
where  $l_X(\boldsymbol{\beta})$ is the log-likelihood of the original linear model. We implement this 'correction' in the calculation of AIC below: 
```{r}
p = 3 # Number of parameters estimated in the models.
AIC.linear <- 2*p - 2*(logLik(mod1) - sum(log(mammals$brain)))
AIC.gamma <- 2*p - 2*logLik(mod.gamma)
AIC.linear
AIC.gamma
```
We see that the linear model is superior to the gamma-GLM with respect to AIC.

### Theoretical skew of log of gamma distribution

Let $Y$ be gamma distributed with shape parameter $a$ and rate parameter $b$.
The moment generating function for $\ln Y$ is
$$
    M_{\ln Y}(t) = \text{E}[e^{t \ln Y}] = \text{E}[Y^t],
$$
where the expectation can be calculated as
$$
\begin{split}
    \text{E}[Y^t] &= \int_0^\infty \frac{b^a}{\Gamma(a)} y^{t+a-1} e^{-b y}\ \text{d}y \\
    &= \frac{b^a}{\Gamma(a)} \int_0^\infty y^{t+a-1} e^{-b y}\ \text{d}y \\
    &= \frac{b^a}{\Gamma(a)} \int_0^\infty \left(\frac{\xi}{b}\right)^{t+a-1} e^{-\xi}\ \frac{\text{d}\xi}{b} \\
    &= \frac{b^{-t}}{\Gamma(a)} \int_0^\infty \xi^{t+a-1} e^{-\xi}\ \text{d}\xi \\
    &= \frac{b^{-t}}{\Gamma(a)}\ \Gamma(t+a),
\end{split}
$$
where we used the substitution $\xi = by$. The cumulant-generating function is defined as the log of the moment generating function, $K(t) := \ln M(t)$, so it follows that
$$
    K_{\ln Y}(t) = \ln M_{\ln Y}(t) = - t \ln b + \ln \Gamma(t+a) - \ln \Gamma(a).
$$
The first cumulat is $K_{\ln Y}^{(1)}(0) = \dfrac{\text{d} K_{\ln Y}(t)}{\text{d} t}\Big|_{t=0} = - \ln b + \psi(a)$, where $\psi^{(0)}(x) = \frac{\Gamma'(x)}{\Gamma(x)}$ is the digamma function. The subsequent cumulants can be derived using the polygamma functions. Recall that
the polygamma function of order $m$ is defined as
$$
    \psi^{(m)}(x) = \frac{\text{d}^{m+1} }{\text{d} x^{m+1}} \ln \Gamma (x),
$$
so the subsequent cumulants are $K_{\ln Y}^{(n)}(t) = \psi^{(n-1)}(a)$ for $n\ge 2$.

The skew of a random variable $X$ with mean $\mu$ and variance $\sigma$ is defined as
$$
    \text{Skew}[X] := \text{E}\left[\left(\frac{X-\mu}{\sigma}\right)^3\right],
$$
so it follows that 
$$
    \text{Skew}[\ln Y] = \frac{\text{E}\left[\left(\ln Y -\text{E}[\ln Y]\right)^3\right]}{\left(\text{Var}({\ln Y})\right)^{3/2}},
$$

where the numerator is the third central moment, equal to the third cumulant and the variance is equal to the second cumulant. Thus the skew of the log of the gamma distribution is
$$
    \text{Skew}[\ln Y] = \frac{\psi^{(2)}(a)}{\left(\psi^{(1)}(a)\right)^{3/2}}.
$$
In R, GLM with gamma-distribution assumes the shape parameter $a$ to be constant. To satisfy this condition, a dispersion parameter $\phi := \frac1a$ is introduced, which can be found in the summary. The polygamma functions are calculated using the library `pracma`.

```{r}
psi <- pracma::psi

phi <- summary(mod.gamma)$dispersion
a <- 1/phi

theory.skew <- psi(2,a) / (psi(1,a))^(3/2)
theory.skew
```
This gives the estimate for the skew of the log mammalian brain size given the body size as `r theory.skew`.


### Sample skew of residuals from the LM

The sample skew of a vector $x$ is defined as
$$
  \text{Sample skew} := \frac{\frac1n \sum_{i=1}^{n}\left(x_i-\bar x\right)^3}{\left[\frac1{n-1} \sum_{i=1}^{n}\left(x_i-\bar x\right)^2\right]^{3/2}},
$$
where $\bar x$ is the mean. For the linear model fitted in (a), we calculate the sample skew of the residuals:
```{r}
# residuals from LM
x <- residuals(mod0)

m.3 <- 1/length(x) * sum((x - mean(x))^3)
s <- sd(x) # = sqrt(1/(length(x)-1) * sum((x-mean(x))^2)) 

sample.skew <- m.3/s^3
sample.skew
```

We observe that the estimated skew of the log-gamma distributed variable is negative and larger in absolute value than the sample skew of the residuals of the linear model from (a). This arguably makes the the gamma-GLM unsuitable, since the log-skew does not match the skew of the residuals. This agrees with the calculations of AIC done earlier. Side note: Why do we compare the skew of $\ln Y$ to the sample skew of the residuals from the linear model, i.e. $\ln Y_{\text{lin}} - \ln \widehat{Y}_{\text{lin}}$? The reason is that $Y_{\text{lin}} \sim \mathcal{N}(\boldsymbol{x}_i^T \boldsymbol{\beta}, \sigma^2)$, i.e. its mean depends on the covariates. To remedy this, we subtract the predictions, which gives us the residuals: $\ln Y_{\text{lin}} - \ln \widehat{Y}_{\text{lin}} \sim \mathcal{N}(0, \sigma^2)$. Then we are safe to calculate the sample skew, since the mean is constant.


\newpage
# Problem 2


## Assumptions

In this problem we apply ordinal multinomial regression to data from Norway Chess 2021. The response variable $y_i$ is the outcome of the $i$'th match. This can be considered an ordered categorical variable
$$
  y_i =
  \begin{cases}
    1 &,\quad \text{white win} \\ 2 &, \quad \text{draw}\\ 3 &, \quad \text{black win},
  \end{cases}
$$
which may depend on relative strength of different players, which player plays white and black and the type of game played. The response can be determined by an underlying latent variable $u_i$, given by
$$
  u_i = -\boldsymbol{x}_i^T \boldsymbol{\beta} + \epsilon_i,
$$
where $\epsilon_i \overset{iid}\sim f$, where $f$ is some standard distribution with cdf $F$. In this model, the event $y_i = r$ occurs if $\theta_{r-1} < u_i \le \theta_{r}$ for some parameters $\{\theta_i\}_{i=0}^3$ satisfying
$$
  -\infty = \theta_0 < \theta_1 < \theta_2 < \theta_3 = \infty.
$$
It follows that
$$
  \text P(y_i \le r) = \text P(u_i \le \theta_r) = \text P(\epsilon_i \le \theta_r + \boldsymbol{x}_i^T \boldsymbol{\beta}) = F(\theta_r + \boldsymbol{x}_i^T \boldsymbol{\beta}),
$$
so the probability of observing a particular outcome of the $i$'th match becomes
$$
  \begin{split}
  \pi_{ir} = P(y_i = r) &= P(y_i \le r) - P(y_i \le r-1)\\
  &= F(\theta_r + \boldsymbol{x}_i^T \boldsymbol{\beta}) - F(\theta_{r-1} + \boldsymbol{x}_i^T \boldsymbol{\beta}).
  \end{split}
$$
This means that our model returns that white wins whenever $u_i \le \theta_1$, draw if $\theta_1 < u_i \le \theta_2$ and black win for $u_i > \theta_2$. Since ordinal regression only depend on relative orderings, we do not need to include the intercept $\beta_0$ in $\boldsymbol{\beta}$, as then the values of the thresholds $\theta$s could be shifted by subtracting the value of the intercept. Using the notation $\boldsymbol{\beta} = \begin{bmatrix}\beta_1 & \cdots & \beta_k\end{bmatrix}^T$, the unknown parameters are therefore $\{ \theta_1, \theta_2, \beta_1, \cdots, \beta_k \}$.

## About the data

Our data set consists of $n=44$ chess matches played with six players, where the set of players are
$$
  \text{players} = \{\text{carlsen},\ \text{firouzja},\ \text{karjakin},\ \text{nepomniachtchi},\ \text{rapport},\ \text{tari}\}.
$$
To get a better understanding of the data set, we give a recap of the tournament regulations. The matches was played over 10 rounds of classical games. The event was a double round-robin, meaning that two players played against each other in two separate rounds, one time with the white pieces and the other time with black. If the result of a the classical game was a draw, then the two players faced each other again to play an armageddon game with the same pieces as in the classical game. In each round, the six players played the three classical games simultaneously. In total, this results in 30 classical games. The remaining 14 comes from the armageddon games.

For each round, the reward was 3 points for winning the classical game and 0 for loosing. If the classical game ended in a draw the armageddon game yielded 1.5 points for winning and 1 point for loosing. If this game also ended in a draw, the winner is declared to be the player with the black pieces. This means that the outcome "draw" and "black win" gave the same points for the armageddon format.

The complete data set can be seen on the next page.

\newpage
```{r}
df <- read.csv('data/Norway\ Chess\ 2021.csv')

df$black = as.factor(df$black)
df$white = as.factor(df$white)
df$type = as.factor(df$type)
df$y <- factor(df$y, ordered=TRUE)
df
```

\newpage

## Assumptions about the residuals

In our analysis, we will assume that the residuals are homoscedastic, are independent and have zero-mean. In addition, we will also assume that the distribution is symmetric (with no skew). There are two common distributions with these properties to consider. The first is the cumulative logit model, given by
$$
  F(x) = \frac{e^x}{1+e^x}, \qquad \epsilon_i \sim \text{Logistic}(0,\ 1).
$$
Using the cumulative model, the residuals are standard logistic distributed. The second model is the cumulative probit model, given by
$$
  F(x) = \Phi(x), \qquad \epsilon_i \sim N(0,\ 1),
$$
where the residuals are normally distributed. We will base our analysis on the cumulative logit model.

Some sources indicate playing white gives a slight advantage over playing black, see for instance here. In addition, the fact that the armageddon games gives the black player no incentive to win the game (since a draw yields the same score), one could argue that the residuals should therefore be slightly negatively skewed. We will ignore this, as the resulting probabilities do not only depended on the shape of $F$ and the value of $\hat u_i = -x_i^T \boldsymbol{\hat\beta}$, but also on the estimated thresholds $\hat \theta_1$ and $\hat \theta_2$.

## Assumptions of the player stregths

There are multiple factors which can influence the outcome of a chess game. In our data we only have access to the player who played white, the player who played black, what type of game it was and which round the game unfolded. The difference in playing styles, psychology and players earlier encounters might give more insight into the relative strength of the players, but we restrict us to this event only. Here we assume that each player is static in the sense that their relative strengths stays fixed throughout the tournament. In the first set of models, we assume that there are no interactions between individual players and other factors.

Later we will investigate some potential interactions in the data. Some players might have particular areas that they are better at than others, such as playing with a specific color or playing armageddon. Others might get tired during the event, resulting in poorer results in the later rounds.

## Model selection

For model selection, we will use AIC and do liklihood-ratio tests comparing different models. Since we have a small number of observations, we also consider AICc, which adds a correction term to AIC, given by
$$
  \text{AICc} := \text{AIC} + \frac{2k^2 + 2k}{n-k-1},
$$
where it is assumed that the residuals are normally distributed. Although the residuals in the logit model is not normal, we will still calculate the AICc value here too.

The liklihood-ratio test are based on change in deviance. For two nested models $M_1$ and $M_2$, where $M_2$ contains the parameters in $M_1$ and an additional $k$ parameters, then under the null hypothesis that $M_1$ is the true model, it follows from Wilk's theorem that the change in deviance between the two models is approximately chi-squared distributed with $k$ degrees of freedom. We will use anova() to infer the corresponding p-value for this test.

\newpage
# Simple models without interactions

Lets first assume that there are no interactions. Define a family of models on the form
$$
u_i = -(\alpha_{w(i)} + \beta_{b(i)} + \delta_{r(i)} + \gamma_{t(i)} ) + \varepsilon_i,
$$
where $\alpha_{w(i)}$ is the effect of player $w(i)$ having white pieces, $\beta_{b(i)}$ is the effect of player $b(i)$ having black pieces, $\delta_{r(i)}$ is the effect of round $r(i)$ and $\gamma_{t(i)}$ is the effect of type $t(i)$ of game played. Since the design matrix must have full rank, R automatically chooses the reference group for the different parameters. This is by default chosen to be the first in the lexicographic order. As so, "carlsen" will be the reference in both $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$, and "armageddon" will be the reference for type of game. As there are more classical games, we change the reference type using the relevel() function.

Let the base model be basic model by `fit.all`. We fit the model in R:
```{r}
library(VGAM)

# change "classic" to reference type
df <- within(df, type <- relevel(type, ref = "classic"))

fit.all <- vglm(y ~ white + black + round + type,
              family=cumulative(parallel = TRUE, link="logitlink"), data=df)

c(AIC = AIC(fit.all), AICc = AICc(fit.all))
anova(fit.all, type = 3, test = "LRT")
summary(fit.all)
```

From the summary, we observe that `round` and `type` has the highest p-values, so we try to fit a model without `round` and a model without `type`. Denote these models by `fit.no_r` and `fit.no_t`, respectively. Then we compare to the base model with a deviance-based LR-test.

```{r}
fit.no_r <-  vglm(y ~ white + black + type,
              family=cumulative(parallel = TRUE, link="logitlink"), data=df)
anova(fit.no_r, fit.all, type = 1, test = 'LRT')
```
```{r}
fit.no_t <-  vglm(y ~ white + black + round,
              family=cumulative(parallel = TRUE, link="logitlink"), data=df)
anova(fit.no_t, fit.all, type = 1, test = 'LRT')
```

The LR-tests get p-values of $0.9379$ and $0.7773$ respectively, which with $\alpha = 0.05$ does not yield evidence that the more complicated model are more suitable than the simpler models. In addition, the AIC and AICc are lower for both the simpler models:
```{r}
c(AIC = AIC(fit.no_r), AICc = AICc(fit.no_r))

c(AIC = AIC(fit.no_t), AICc = AICc(fit.no_t))
```
Based on this, we choose to investigate a simpler model where $\delta = 0$ and $\gamma = 0$. This means we are investigating the model with the form
$$
  u_i = -(\alpha_{w(i)} + \beta_{b(i)} ) + \varepsilon_i,
$$
which suggests that the outcome of each game only depend on the relative strengths of playing white and black. Denote this simpler model by `fit.no_rt`. First we compare this model to the first model `fit.all` to test if removing these two parameters are fine.

```{r}
fit.no_rt <-  vglm(y ~ white + black,
                           family=cumulative(parallel = TRUE, link="logitlink"), data=df)
anova(fit.no_rt, fit.all, type = 1, test = 'LRT')
```
The p-value of $0.9607$ suggests again that there are no evidence that the more complicated model `fit.all` is better than the simple model. The AIC for the simple model is:
```{r}
c(AIC = AIC(fit.no_rt), AICc = AICc(fit.no_rt))
```

\newpage
# Testing different relative strengths of players

Since it could be argued that the given skill level of a player could be the same for playing both white and black, we next consider a model where the effect of playing white is equal to the effect of playing black, meaning $\alpha_p = - \beta_p, \quad \forall p \in \text{players}$. This would be a simpler model since there are fewer parameters to estimate. The model becomes
$$
u_i = -(\alpha_{w(i)} - \alpha_{b(i)} ) + \varepsilon_i.
$$

To make this new model, we dummy-encode the players, with value 1 if the player is white and -1 if the player is black. To make the design matrix have full rank, we remove `carlsen` from the formulas.
```{r}
dummy_cols <- fastDummies::dummy_cols

df <- dummy_cols(df, select_columns = "white")
for(i in 1:nrow(df)){
    df[i, paste("white", df$black[i], sep="_")] = -1
}
# change columns ('white_name' -> 'name')
colnames(df)[6:11] <- c("carlsen", "firouzja","karjakin", "nepo", "rapport", "tari")
```

```{r}
fit.simple <- vglm(y ~ firouzja + karjakin + nepo + rapport + tari,
              family=cumulative(parallel = TRUE, link="logitlink"), data=df)
summary(fit.simple)
c(AIC = AIC(fit.simple), AICc = AICc(fit.simple))
```
Since `fit.no_rt` and `fit.simple` not nested models (they use different covariates), we cannot use the simple LR-test performed earlier. However, comparing `fit.no_rt` with `fit.simple`, we observe that `fit.simple` has a lower AIC, suggesting that it fitted the data better.

From the models so far, we see that the model with the lowest AIC and AICc is `fit.simple`, the model consisting of only the relative strengths of each player. In the summary, we see that the relative strength of some players are close to one another, in particular "firouzja" and "rapport", but also note that "nepomniachtchi" and "karjakin" are comparable. Let us try fitting a model where we assume that the relative strength of "firouzja" and "rapport" are equal. Thus our model becomes
$$
  u_i = -(\alpha_{w(i)} - \alpha_{b(i)}) + \varepsilon_i,
$$
where $\alpha_{\text{firouzja}} = \alpha_{\text{rapport}}$. In R we can make this model by simply adding the columns `firourzja` and `rapport`, as both players cannot play the same color simultaneously. Denote this model by `fit.simple2`. We also define the model where in addition to `firourzja` and `rapport`, we assume that `nepomniachtchi` and `karjakin` also have the same strength. Define this model by `fit.simple3`.

```{r}
fit.simple2 <- vglm(y ~ I(firouzja + rapport) + nepo + karjakin + tari,
              family=cumulative(parallel = TRUE, link="logitlink"), data=df)
c(AIC = AIC(fit.simple2), AICc = AICc(fit.simple2))
```

```{r}
fit.simple3 <- vglm(y ~ I(firouzja + rapport) + I(nepo + karjakin) + tari,
              family=cumulative(parallel = TRUE, link="logitlink"), data=df)
c(AIC = AIC(fit.simple3), AICc = AICc(fit.simple3))
```
Then we use the deviance-based LR-test comparing the simple models:
```{r}
anova(fit.simple2, fit.simple, type = 1, test = 'LRT')
anova(fit.simple3, fit.simple, type = 1, test = 'LRT')
anova(fit.simple2, fit.simple3, type = 1, test = 'LRT')
```
Again, we see no clear evidence to suggest that the more complex model is preferred. To test the limit as how simple the model can be made, we define a model where all players except `carlsen` is assumed to have the same strength. Define this model by `fit.simple4`. Thus our model becomes
$$
  u_i = -(\alpha_{w(i)} - \alpha_{b(i)}) + \varepsilon_i,
$$
where $\alpha_{p} = \alpha_{q}\ \forall p,q \in \text{players} \setminus \{\text{carlsen}\}$.

```{r}
fit.simple4 <- vglm(y ~ I(firouzja + rapport+ nepo + karjakin + tari),
              family=cumulative(parallel = TRUE, link="logitlink"), data=df)
summary(fit.simple4)
c(AIC = AIC(fit.simple4), AICc = AICc(fit.simple4))
```
The LR-test becomes:
```{r}
anova(fit.simple4, fit.simple, type = 1, test = 'LRT')
```
This, in turn, gives no clear indication of keeping the more complicated model. However, this might not be accurate, as the model gives higher AIC than `fit.simple2`. A problem with these tests is that we have a small number of observations, and the deviance-based LR-test is not necessarily accurate. The best model so far is the `fit.simple4`, where we in effect have four levels of strengths.

\newpage
# Testing player interactions with color, round and type

Next we want to test some models where there are interactions among players and certain aspects. Since the players potentially have different playing styles, we want to test whether some players do particularly well when playing with white compared to playing with black. To do so, we add a column for each player indicating if they play with white or black using dummy-encoding. From the summary of `fit.all`, we see that three players had p-values $<0.2$ for playing with white. These players are `nepomniachtchi`, `karjakin` and `tari`. Using the model `fit.simple` as the base model, we try adding the interaction between playing white for these players:
```{r}
df <- dummy_cols(df, select_columns = c("white", "black"))

fit.interaction.color <- vglm(y ~ firouzja + rapport + nepo + karjakin + tari +
                          white_nepomniachtchi + white_karjakin + white_tari,
                          family=cumulative(parallel = TRUE, link="logitlink"), data=df)
c(AIC = AIC(fit.interaction.color), AICc = AICc(fit.interaction.color))
anova(fit.interaction.color, fit.simple, type = 1, test = 'LRT')
```
The higher AIC and LR-test gives no evidence for selecting the more complicated model.

Next we test the interaction between player and round. The intuition behind this is that the players may become tired during the event, or might loose or gain motivation. To test this effect, we include an interaction between the players and the round in the event. Since we only care if the player is present or not, we have to take the absolute value. (if not the effect is reversed for playing black). Define this model:
```{r}
fit.interaction.round <- vglm(y ~ firouzja + rapport + nepo + karjakin + tari +
                         abs(carlsen):round + abs(firouzja):round + abs(rapport):round
                         + abs(nepo):round + abs(karjakin):round + abs(tari):round,
                        family=cumulative(parallel = TRUE, link="logitlink"), data=df)
summary(fit.interaction.round)
```
The summary gives a p-value $<0.2$ for the players `carlsen`, `nepomniachtchi` and `tari`, with the p-value for `nepomniachtchi` being below $0.1$. Judging by the sign of the fitted parameters, this model suggests that `carlsen` played better towards the end of the event, while `nepomniachtchi` and `tari` worsened their play.
Let's try fitting a model with the interaction present for only `nepomniachtchi` first:
```{r}
fit.interaction.round_nepo <- vglm(y ~ firouzja + rapport + nepo + karjakin + tari
         + abs(nepo):round, family=cumulative(parallel = TRUE, link="logitlink"), data=df)
c(AIC = AIC(fit.interaction.round_nepo), AICc = AICc(fit.interaction.round_nepo))
anova(fit.interaction.round_nepo, fit.simple, type = 1, test = 'LRT')
```
The p-value of $0.182$ almost suggests that this interaction is significant. However, the AIC did not improve. 

The last interaction we want to test is between player and type of match played. As some players might adapt their playing style for armageddon, we fit a model with an interaction between the player and type:
```{r}
fit.interaction.type <- vglm(y ~ firouzja + rapport + nepo + karjakin + tari + firouzja:type
                         + rapport:type + nepo:type + karjakin:type + tari:type,
                        family=cumulative(parallel = TRUE, link="logitlink"), data=df)
summary(fit.interaction.type)
c(AIC = AIC(fit.interaction.type), AICc = AICc(fit.interaction.type))
anova(fit.interaction.type, fit.simple, type = 1, test = 'LRT')
```
From the summary, only the player `karjakin` has a p-value less than $0.1$. Now we fit a model with this interaction:
```{r}
fit.interaction.type_karjakin <- vglm(y ~ firouzja + rapport + nepo + karjakin + tari
                    + karjakin:type,
                    family=cumulative(parallel = TRUE, link="logitlink"), data=df)
summary(fit.interaction.type_karjakin)
c(AIC = AIC(fit.interaction.type_karjakin), AICc = AICc(fit.interaction.type_karjakin))
anova(fit.interaction.type_karjakin, fit.simple, type = 1, test = 'LRT')
```
From the LR-tets, we see that there are evidence for rejecting `fit.simple` in favor of the new model including the interaction between player `karjakin` and `type` of game played. As seen in the summary of this model, we note that the playing strength of `firouzja` and `rapport` are again comparable. As a last test, let's the current best model where we assume that the playing strength of these two players are equal. Define this model as `fit.last` and compare it with the current model:
```{r}
fit.last <- vglm(y ~ I(firouzja + rapport) + nepo + karjakin + tari + karjakin:type,
                    family=cumulative(parallel = TRUE, link="logitlink"), data=df)
c(AIC = AIC(fit.last), AICc = AICc(fit.last))
```
The model `fit.last` has a lower AIC, which suggests that the last model is better.


# Conclusion
We have seen that it is possible to apply ordinal multinomial regression to the data from Norway Chess 2021. Even though there are few covariates and observations, we still had to limit our search towards finding a good model for predicting the outcomes of the games. Using AIC and the liklihood-ratio tests when applicable, we could compare the resulting candidate models and arrive at a reasonable model.

Our extensive search hinted at certain players having different strengths, but gave mostly no definitive conclusions. For instance, our findings suggest that some players are better at playing with white than black, better at playing armageddon or that their performance changed during the event. This resulted in finding a model where the relative strength of the players was most significant.

We also found the interaction between Karjakin and armageddon to be significant. This find might be false, as there are very few observations to infer from. To avoid the possibility of overfitting, we could then choose the simpler model consisting of just the relative strengths among the players. Another option could be to include the chess ratings of the players in the model, as the rating is based on prior performance, and could indicate future performance.


